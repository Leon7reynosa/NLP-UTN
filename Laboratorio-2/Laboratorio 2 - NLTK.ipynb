{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(138,0,3)\">Laboratorio 2</h1>\n",
    "<h3> Part of Speech</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:rgb(0,1,84)\">Alumno: Leon Lautaro Reynosa</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:rgb(0,1,84)\">Legajo: 163262-0</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:rgb(0,1,84)\">Profesor: Hernan Borre</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:rgb(0,1,84)\">Materia: Procesamiento del Lenguaje Natural  (K3572) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. ¿De que se trata??</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Este lab se enfoca en aplicar el tagging (marcado o etiquetado, en español) Part of Speech\n",
    "(POS) y de explorar los métodos que ofrece NLTK para asingar POS automáticamente.\n",
    "Para más prácticas e información sobre este tópico, puede visitar:\n",
    "http://www.nltk.org/book/ch05.html</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. NLTK environment</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Importamos la libreria de NTLK al entorno activo, y tambien bajar algunos corpora que vamos a usar en el lab.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Part of speech tagsets</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Los POS tagger asignan etiquetas a palabras. Los tags son tomados de un tagset. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"NN*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"VB*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, singular, common\n",
      "    failure burden court fire appointment awarding compensation Mayor\n",
      "    interim committee fact effect airport management surveillance jail\n",
      "    doctor intern extern night weekend duty legislation Tax Office ...\n",
      "NN$: noun, singular, common, genitive\n",
      "    season's world's player's night's chapter's golf's football's\n",
      "    baseball's club's U.'s coach's bride's bridegroom's board's county's\n",
      "    firm's company's superintendent's mob's Navy's ...\n",
      "NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular\n",
      "    water's camera's sky's kid's Pa's heat's throat's father's money's\n",
      "    undersecretary's granite's level's wife's fat's Knife's fire's name's\n",
      "    hell's leg's sun's roulette's cane's guy's kind's baseball's ...\n",
      "NN+HVD: noun, singular, common + verb 'to have', past tense\n",
      "    Pa'd\n",
      "NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular\n",
      "    guy's Knife's boat's summer's rain's company's\n",
      "NN+IN: noun, singular, common + preposition\n",
      "    buncha\n",
      "NN+MD: noun, singular, common + modal auxillary\n",
      "    cowhand'd sun'll\n",
      "NN+NN: noun, singular, common, hyphenated pair\n",
      "    stomach-belly\n",
      "NNS: noun, plural, common\n",
      "    irregularities presentments thanks reports voters laws legislators\n",
      "    years areas adjustments chambers $100 bonds courts sales details raises\n",
      "    sessions members congressmen votes polls calls ...\n",
      "NNS$: noun, plural, common, genitive\n",
      "    taxpayers' children's members' States' women's cutters' motorists'\n",
      "    steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'\n",
      "    Employers' secretaries' Rogues' ...\n",
      "NNS+MD: noun, plural, common + modal auxillary\n",
      "    duds'd oystchers'll\n",
      "NP: noun, singular, proper\n",
      "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
      "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
      "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
      "NP$: noun, singular, proper, genitive\n",
      "    Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n",
      "    Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n",
      "    Shea's Palmer's Arnold's Broglio's ...\n",
      "NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular\n",
      "    W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's\n",
      "    Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's\n",
      "    Lucille's Springfield's Arlene's\n",
      "NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular\n",
      "    Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's\n",
      "NP+MD: noun, singular, proper + modal auxillary\n",
      "    Gyp'll John'll\n",
      "NPS: noun, plural, proper\n",
      "    Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen\n",
      "    Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British\n",
      "    Dixiecrats Mississippians Congresses ...\n",
      "NPS$: noun, plural, proper, genitive\n",
      "    Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'\n",
      "    Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'\n",
      "    Gershwins' Adventists' Negroes' Catholics' ...\n",
      "NR: noun, singular, adverbial\n",
      "    Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow\n",
      "    tonight West East Saturday west left east downtown north northeast\n",
      "    southeast northwest North South right ...\n",
      "NR$: noun, singular, adverbial, genitive\n",
      "    Saturday's Monday's yesterday's tonight's tomorrow's Sunday's\n",
      "    Wednesday's Friday's today's Tuesday's West's Today's South's\n",
      "NR+MD: noun, singular, adverbial + modal auxillary\n",
      "    today'll\n",
      "NRS: noun, plural, adverbial\n",
      "    Sundays Mondays Saturdays Wednesdays Souths Fridays\n"
     ]
    }
   ],
   "source": [
    " nltk.help.brown_tagset(\"NN*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base: uninflected present, imperative or infinitive\n",
      "    investigate find act follow inure achieve reduce take remedy re-set\n",
      "    distribute realize disable feel receive continue place protect\n",
      "    eliminate elaborate work permit run enter force ...\n",
      "VB+AT: verb, base: uninflected present or infinitive + article\n",
      "    wanna\n",
      "VB+IN: verb, base: uninflected present, imperative or infinitive + preposition\n",
      "    lookit\n",
      "VB+JJ: verb, base: uninflected present, imperative or infinitive + adjective\n",
      "    die-dead\n",
      "VB+PPO: verb, uninflected present tense + pronoun, personal, accusative\n",
      "    let's lemme gimme\n",
      "VB+RP: verb, imperative + adverbial particle\n",
      "    g'ahn c'mon\n",
      "VB+TO: verb, base: uninflected present, imperative or infinitive + infinitival to\n",
      "    wanta wanna\n",
      "VB+VB: verb, base: uninflected present, imperative or infinitive; hypenated pair\n",
      "    say-speak\n",
      "VBD: verb, past tense\n",
      "    said produced took recommended commented urged found added praised\n",
      "    charged listed became announced brought attended wanted voted defeated\n",
      "    received got stood shot scheduled feared promised made ...\n",
      "VBG: verb, present participle or gerund\n",
      "    modernizing improving purchasing Purchasing lacking enabling pricing\n",
      "    keeping getting picking entering voting warning making strengthening\n",
      "    setting neighboring attending participating moving ...\n",
      "VBG+TO: verb, present participle + infinitival to\n",
      "    gonna\n",
      "VBN: verb, past participle\n",
      "    conducted charged won received studied revised operated accepted\n",
      "    combined experienced recommended effected granted seen protected\n",
      "    adopted retarded notarized selected composed gotten printed ...\n",
      "VBN+TO: verb, past participle + infinitival to\n",
      "    gotta\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    deserves believes receives takes goes expires says opposes starts\n",
      "    permits expects thinks faces votes teaches holds calls fears spends\n",
      "    collects backs eliminates sets flies gives seeks reads ...\n"
     ]
    }
   ],
   "source": [
    " nltk.help.brown_tagset(\"VB*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4. Explorando el tagger corpora</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Las probabilidades de un algoritmos de POS tagging son estimadas con un corpora.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wsj_0001.mrg',\n",
       " 'wsj_0002.mrg',\n",
       " 'wsj_0003.mrg',\n",
       " 'wsj_0004.mrg',\n",
       " 'wsj_0005.mrg',\n",
       " 'wsj_0006.mrg',\n",
       " 'wsj_0007.mrg',\n",
       " 'wsj_0008.mrg',\n",
       " 'wsj_0009.mrg',\n",
       " 'wsj_0010.mrg',\n",
       " 'wsj_0011.mrg',\n",
       " 'wsj_0012.mrg',\n",
       " 'wsj_0013.mrg',\n",
       " 'wsj_0014.mrg',\n",
       " 'wsj_0015.mrg',\n",
       " 'wsj_0016.mrg',\n",
       " 'wsj_0017.mrg',\n",
       " 'wsj_0018.mrg',\n",
       " 'wsj_0019.mrg',\n",
       " 'wsj_0020.mrg',\n",
       " 'wsj_0021.mrg',\n",
       " 'wsj_0022.mrg',\n",
       " 'wsj_0023.mrg',\n",
       " 'wsj_0024.mrg',\n",
       " 'wsj_0025.mrg',\n",
       " 'wsj_0026.mrg',\n",
       " 'wsj_0027.mrg',\n",
       " 'wsj_0028.mrg',\n",
       " 'wsj_0029.mrg',\n",
       " 'wsj_0030.mrg',\n",
       " 'wsj_0031.mrg',\n",
       " 'wsj_0032.mrg',\n",
       " 'wsj_0033.mrg',\n",
       " 'wsj_0034.mrg',\n",
       " 'wsj_0035.mrg',\n",
       " 'wsj_0036.mrg',\n",
       " 'wsj_0037.mrg',\n",
       " 'wsj_0038.mrg',\n",
       " 'wsj_0039.mrg',\n",
       " 'wsj_0040.mrg',\n",
       " 'wsj_0041.mrg',\n",
       " 'wsj_0042.mrg',\n",
       " 'wsj_0043.mrg',\n",
       " 'wsj_0044.mrg',\n",
       " 'wsj_0045.mrg',\n",
       " 'wsj_0046.mrg',\n",
       " 'wsj_0047.mrg',\n",
       " 'wsj_0048.mrg',\n",
       " 'wsj_0049.mrg',\n",
       " 'wsj_0050.mrg',\n",
       " 'wsj_0051.mrg',\n",
       " 'wsj_0052.mrg',\n",
       " 'wsj_0053.mrg',\n",
       " 'wsj_0054.mrg',\n",
       " 'wsj_0055.mrg',\n",
       " 'wsj_0056.mrg',\n",
       " 'wsj_0057.mrg',\n",
       " 'wsj_0058.mrg',\n",
       " 'wsj_0059.mrg',\n",
       " 'wsj_0060.mrg',\n",
       " 'wsj_0061.mrg',\n",
       " 'wsj_0062.mrg',\n",
       " 'wsj_0063.mrg',\n",
       " 'wsj_0064.mrg',\n",
       " 'wsj_0065.mrg',\n",
       " 'wsj_0066.mrg',\n",
       " 'wsj_0067.mrg',\n",
       " 'wsj_0068.mrg',\n",
       " 'wsj_0069.mrg',\n",
       " 'wsj_0070.mrg',\n",
       " 'wsj_0071.mrg',\n",
       " 'wsj_0072.mrg',\n",
       " 'wsj_0073.mrg',\n",
       " 'wsj_0074.mrg',\n",
       " 'wsj_0075.mrg',\n",
       " 'wsj_0076.mrg',\n",
       " 'wsj_0077.mrg',\n",
       " 'wsj_0078.mrg',\n",
       " 'wsj_0079.mrg',\n",
       " 'wsj_0080.mrg',\n",
       " 'wsj_0081.mrg',\n",
       " 'wsj_0082.mrg',\n",
       " 'wsj_0083.mrg',\n",
       " 'wsj_0084.mrg',\n",
       " 'wsj_0085.mrg',\n",
       " 'wsj_0086.mrg',\n",
       " 'wsj_0087.mrg',\n",
       " 'wsj_0088.mrg',\n",
       " 'wsj_0089.mrg',\n",
       " 'wsj_0090.mrg',\n",
       " 'wsj_0091.mrg',\n",
       " 'wsj_0092.mrg',\n",
       " 'wsj_0093.mrg',\n",
       " 'wsj_0094.mrg',\n",
       " 'wsj_0095.mrg',\n",
       " 'wsj_0096.mrg',\n",
       " 'wsj_0097.mrg',\n",
       " 'wsj_0098.mrg',\n",
       " 'wsj_0099.mrg',\n",
       " 'wsj_0100.mrg',\n",
       " 'wsj_0101.mrg',\n",
       " 'wsj_0102.mrg',\n",
       " 'wsj_0103.mrg',\n",
       " 'wsj_0104.mrg',\n",
       " 'wsj_0105.mrg',\n",
       " 'wsj_0106.mrg',\n",
       " 'wsj_0107.mrg',\n",
       " 'wsj_0108.mrg',\n",
       " 'wsj_0109.mrg',\n",
       " 'wsj_0110.mrg',\n",
       " 'wsj_0111.mrg',\n",
       " 'wsj_0112.mrg',\n",
       " 'wsj_0113.mrg',\n",
       " 'wsj_0114.mrg',\n",
       " 'wsj_0115.mrg',\n",
       " 'wsj_0116.mrg',\n",
       " 'wsj_0117.mrg',\n",
       " 'wsj_0118.mrg',\n",
       " 'wsj_0119.mrg',\n",
       " 'wsj_0120.mrg',\n",
       " 'wsj_0121.mrg',\n",
       " 'wsj_0122.mrg',\n",
       " 'wsj_0123.mrg',\n",
       " 'wsj_0124.mrg',\n",
       " 'wsj_0125.mrg',\n",
       " 'wsj_0126.mrg',\n",
       " 'wsj_0127.mrg',\n",
       " 'wsj_0128.mrg',\n",
       " 'wsj_0129.mrg',\n",
       " 'wsj_0130.mrg',\n",
       " 'wsj_0131.mrg',\n",
       " 'wsj_0132.mrg',\n",
       " 'wsj_0133.mrg',\n",
       " 'wsj_0134.mrg',\n",
       " 'wsj_0135.mrg',\n",
       " 'wsj_0136.mrg',\n",
       " 'wsj_0137.mrg',\n",
       " 'wsj_0138.mrg',\n",
       " 'wsj_0139.mrg',\n",
       " 'wsj_0140.mrg',\n",
       " 'wsj_0141.mrg',\n",
       " 'wsj_0142.mrg',\n",
       " 'wsj_0143.mrg',\n",
       " 'wsj_0144.mrg',\n",
       " 'wsj_0145.mrg',\n",
       " 'wsj_0146.mrg',\n",
       " 'wsj_0147.mrg',\n",
       " 'wsj_0148.mrg',\n",
       " 'wsj_0149.mrg',\n",
       " 'wsj_0150.mrg',\n",
       " 'wsj_0151.mrg',\n",
       " 'wsj_0152.mrg',\n",
       " 'wsj_0153.mrg',\n",
       " 'wsj_0154.mrg',\n",
       " 'wsj_0155.mrg',\n",
       " 'wsj_0156.mrg',\n",
       " 'wsj_0157.mrg',\n",
       " 'wsj_0158.mrg',\n",
       " 'wsj_0159.mrg',\n",
       " 'wsj_0160.mrg',\n",
       " 'wsj_0161.mrg',\n",
       " 'wsj_0162.mrg',\n",
       " 'wsj_0163.mrg',\n",
       " 'wsj_0164.mrg',\n",
       " 'wsj_0165.mrg',\n",
       " 'wsj_0166.mrg',\n",
       " 'wsj_0167.mrg',\n",
       " 'wsj_0168.mrg',\n",
       " 'wsj_0169.mrg',\n",
       " 'wsj_0170.mrg',\n",
       " 'wsj_0171.mrg',\n",
       " 'wsj_0172.mrg',\n",
       " 'wsj_0173.mrg',\n",
       " 'wsj_0174.mrg',\n",
       " 'wsj_0175.mrg',\n",
       " 'wsj_0176.mrg',\n",
       " 'wsj_0177.mrg',\n",
       " 'wsj_0178.mrg',\n",
       " 'wsj_0179.mrg',\n",
       " 'wsj_0180.mrg',\n",
       " 'wsj_0181.mrg',\n",
       " 'wsj_0182.mrg',\n",
       " 'wsj_0183.mrg',\n",
       " 'wsj_0184.mrg',\n",
       " 'wsj_0185.mrg',\n",
       " 'wsj_0186.mrg',\n",
       " 'wsj_0187.mrg',\n",
       " 'wsj_0188.mrg',\n",
       " 'wsj_0189.mrg',\n",
       " 'wsj_0190.mrg',\n",
       " 'wsj_0191.mrg',\n",
       " 'wsj_0192.mrg',\n",
       " 'wsj_0193.mrg',\n",
       " 'wsj_0194.mrg',\n",
       " 'wsj_0195.mrg',\n",
       " 'wsj_0196.mrg',\n",
       " 'wsj_0197.mrg',\n",
       " 'wsj_0198.mrg',\n",
       " 'wsj_0199.mrg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ahora, para ver el archivo junto con los POS tags, se puede usar:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('chairman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Elsevier', 'NNP'),\n",
       " ('N.V.', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Dutch', 'NNP'),\n",
       " ('publishing', 'VBG'),\n",
       " ('group', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.tagged_words(\"wsj_0001.mrg\")[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Imprimimos las primeras 100 palabras en formato bonito.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cien_palabras = treebank.tagged_words(\"wsj_0003.mrg\")[0:100]\n",
    "cien_palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'DT')\n",
      "('form', 'NN')\n",
      "('of', 'IN')\n",
      "('asbestos', 'NN')\n",
      "('once', 'RB')\n",
      "('used', 'VBN')\n",
      "('*', '-NONE-')\n",
      "('*', '-NONE-')\n",
      "('to', 'TO')\n",
      "('make', 'VB')\n",
      "('Kent', 'NNP')\n",
      "('cigarette', 'NN')\n",
      "('filters', 'NNS')\n",
      "('has', 'VBZ')\n",
      "('caused', 'VBN')\n",
      "('a', 'DT')\n",
      "('high', 'JJ')\n",
      "('percentage', 'NN')\n",
      "('of', 'IN')\n",
      "('cancer', 'NN')\n",
      "('deaths', 'NNS')\n",
      "('among', 'IN')\n",
      "('a', 'DT')\n",
      "('group', 'NN')\n",
      "('of', 'IN')\n",
      "('workers', 'NNS')\n",
      "('exposed', 'VBN')\n",
      "('*', '-NONE-')\n",
      "('to', 'TO')\n",
      "('it', 'PRP')\n",
      "('more', 'RBR')\n",
      "('than', 'IN')\n",
      "('30', 'CD')\n",
      "('years', 'NNS')\n",
      "('ago', 'IN')\n",
      "(',', ',')\n",
      "('researchers', 'NNS')\n",
      "('reported', 'VBD')\n",
      "('0', '-NONE-')\n",
      "('*T*-1', '-NONE-')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('asbestos', 'NN')\n",
      "('fiber', 'NN')\n",
      "(',', ',')\n",
      "('crocidolite', 'NN')\n",
      "(',', ',')\n",
      "('is', 'VBZ')\n",
      "('unusually', 'RB')\n",
      "('resilient', 'JJ')\n",
      "('once', 'IN')\n",
      "('it', 'PRP')\n",
      "('enters', 'VBZ')\n",
      "('the', 'DT')\n",
      "('lungs', 'NNS')\n",
      "(',', ',')\n",
      "('with', 'IN')\n",
      "('even', 'RB')\n",
      "('brief', 'JJ')\n",
      "('exposures', 'NNS')\n",
      "('to', 'TO')\n",
      "('it', 'PRP')\n",
      "('causing', 'VBG')\n",
      "('symptoms', 'NNS')\n",
      "('that', 'WDT')\n",
      "('*T*-1', '-NONE-')\n",
      "('show', 'VBP')\n",
      "('up', 'RP')\n",
      "('decades', 'NNS')\n",
      "('later', 'JJ')\n",
      "(',', ',')\n",
      "('researchers', 'NNS')\n",
      "('said', 'VBD')\n",
      "('0', '-NONE-')\n",
      "('*T*-2', '-NONE-')\n",
      "('.', '.')\n",
      "('Lorillard', 'NNP')\n",
      "('Inc.', 'NNP')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('unit', 'NN')\n",
      "('of', 'IN')\n",
      "('New', 'JJ')\n",
      "('York-based', 'JJ')\n",
      "('Loews', 'NNP')\n",
      "('Corp.', 'NNP')\n",
      "('that', 'WDT')\n",
      "('*T*-2', '-NONE-')\n",
      "('makes', 'VBZ')\n",
      "('Kent', 'NNP')\n",
      "('cigarettes', 'NNS')\n",
      "(',', ',')\n",
      "('stopped', 'VBD')\n",
      "('using', 'VBG')\n",
      "('crocidolite', 'NN')\n",
      "('in', 'IN')\n",
      "('its', 'PRP$')\n",
      "('Micronite', 'NN')\n",
      "('cigarette', 'NN')\n",
      "('filters', 'NNS')\n"
     ]
    }
   ],
   "source": [
    " for p in cien_palabras:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>5. Contando desde un corpora</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A veces, nos preguntamos (para entender mejor el texto que estamos procesando, entre\n",
    "otras cosas), si una palabra en particular, aparece más frecuentemente como sustantivo o\n",
    "como verbo. Podemos entonces contar la frecuencia en un corpora para ver los resultados\n",
    "empíricos de nuestra duda.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>En este caso, vamos a ver si la palabra inglesa ‘race’ (carrera) aparece más veces como\n",
    "verbo o como sustantivo, ya que puede adoptar los dos significados.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> creamos primero dos tuplas correspondiendo a nuestras dos hipótesis:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('race', 'NN')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race1 = nltk.tag.str2tuple('race/NN')\n",
    "race1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('race', 'VB')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race2 = nltk.tag.str2tuple('race/VB')\n",
    "race2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>usaremos también el Brown corpus para los estimados.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.tagged_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>¿Cuál es el tamaño del Brown corpus?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words().count(race1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words().count(race2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>¿Cuál es el uso más frecuente, cómo verbo o como sustantivo en el Brown corpus?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Podemos notar que el uso de la palabra \"race\" en el Brown corpus, aparece mas veces com un sustantivo que como un verbo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> ¿Era lo que te imaginabas?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, era lo que me imaginaba por que usualmente es mas usado '\"race\" como un sustantivo que como un verbo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El POS tagger HMM que se detalla en las diapositivas de la clase, usa dos fuentes de\n",
    "información. Una es la probabilidad de una palabra dado un tag particular, p(wi|ti). <h4>¿Cuál es la\n",
    "otra fuente de información que te ayuda a tagear una oración?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La otra fuente de información que utiliza para tagear una oración es la probabilidad del tag siguiente, dado el tag que viene previo a el.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>6. Aplicando POS tagging a una nueva oración</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Estudiamos el algoritmo HMM Viterbi para POS tagging. NLTK incluye una implementación\n",
    "del HMM tagger así como un par de otros.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>El primer tagger que usaremos sería el UnigramTagger. Basado en el nombre, podrías\n",
    "adivinar que va a estar haciendo algo realmente simple y probablemente no se usa en\n",
    "ningún contexto. Así es! El UnigramTagger guarda el tag más frecuente para cada palabra\n",
    "sobre los datos de entretamiento (trainning set). Cuando ve que una palabra en una oración,\n",
    "le asignará el tag más frecuente a la misma. Así que, podemos decir que no tiene en cuenta\n",
    "el contexto.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Primero vamos a entregar un tagger de unigrams usando 5000 oraciones del Brown corpus\n",
    "como training data. Usando el argumento categories=news seleccionamos solo los\n",
    "documentos de noticias de la colección diversa que tiene el corpus Brown.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.tag.UnigramTagger(brown.tagged_sents(categories='news')[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ahora unigram_tagger es un objeto que contiene el modelo entrenado. Aplicamos este modelo a\n",
    "nuestra frase de prueba “The Secretariat is expected to race tomorrow.” PARA! Antes de ejecutar\n",
    "este código, qué TAG te parece que le será asignado a la palabra “race” en nuestro modelo?\n",
    "(sustantivo o verbo?)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = \"The Secretariat is expected to race tomorrow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_tok = word_tokenize(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Secretariat', 'NN-TL'),\n",
       " ('is', 'BEZ'),\n",
       " ('expected', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('race', 'NN'),\n",
       " ('tomorrow', 'NR'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " unigram_tagger.tag(S_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Acertaste?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ahora corré el HMM tagger en esta oración, te dio los mismos tags?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_tagger =nltk.hmm.HiddenMarkovModelTrainer().train_supervised(brown.tagged_sents(categories=\"news\")[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Secretariat', 'NN-TL'),\n",
       " ('is', 'BEZ'),\n",
       " ('expected', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('race', 'VB'),\n",
       " ('tomorrow', 'NR'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " hmm_tagger.tag(S_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Qué tag le asignó este modelo a la palabra “race”?</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Con el HMM podemos ver que se le asigno el tag VB, es decir que lo asimila como un verbo, en cambio, el unigram_tagger lo asigna como un NN, es decir un sustantivo.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ahora hagamos este ejercicio con el NLTK book. Es posible encontrar títulos de noticias\n",
    "ambiguos como este:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\"Juvenile Court to Try Shooting Defendant”</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Manualmente (a mano) taggea este titular para ver si tu conocimiento del Part of speech tagging\n",
    "remueve la ambigüedad. Una aproximación está bien, no hace falta que uses exactamente los tags\n",
    "del tagset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[('Juvenile', 'NN'),\n",
    " ('Court', 'VB'),\n",
    " ('to', 'IN'),\n",
    " ('Try', 'VB'),\n",
    " ('Shooting', 'VB'),\n",
    " ('Defendant', 'NN')]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ahora corré el HMM tagger en esta oración, te dio los mismos tags?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = \"Juvenile Court to Try Shooting Defendant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence_tok = word_tokenize(Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Juvenile', 'JJ-TL'),\n",
       " ('Court', 'NN-TL'),\n",
       " ('to', 'IN'),\n",
       " ('Try', 'AT'),\n",
       " ('Shooting', 'AT'),\n",
       " ('Defendant', 'AT')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " hmm_tagger.tag(Sentence_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Podemos notar que la respuesta del HMM no es la misma de la que tageamos manualmente</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
